{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo ```chunks.bin``` fue construido en el notebook ```eda_documents.ipynb```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebasjp/repos/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de documentos: 563\n",
      "page_content='baja de tasas de interes facilita la compra de vivienda en 2024\n",
      "la compra de vivienda para muchos colombianos se ha visto afectada por diferentes factores economicos como la inflacion, devaluacion de la moneda, entre otros. frente a este panorama, muchos sectores, como el financiero, presentan medidas para la reactivacion de la economia.\n",
      "el banco de la republica viene haciendo reduccion de tasas de interes desde febrero del 2024, llegando en julio a 11.25%, y' metadata={'id': '2a3d5c52', 'title': 'baja de tasas de interes facilita la compra de vivienda en 2024'}\n"
     ]
    }
   ],
   "source": [
    "with open('chunks.bin', 'rb') as f_in:\n",
    "    documents = pickle.load(f_in)\n",
    "\n",
    "print(\"# de documentos:\", len(documents))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    {\n",
    "        \"id_doc\": doc.metadata[\"id\"],\n",
    "        \"chunk\": doc.page_content   \n",
    "    }\n",
    "    for doc in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_doc': '2a3d5c52',\n",
       " 'chunk': 'baja de tasas de interes facilita la compra de vivienda en 2024\\nla compra de vivienda para muchos colombianos se ha visto afectada por diferentes factores economicos como la inflacion, devaluacion de la moneda, entre otros. frente a este panorama, muchos sectores, como el financiero, presentan medidas para la reactivacion de la economia.\\nel banco de la republica viene haciendo reduccion de tasas de interes desde febrero del 2024, llegando en julio a 11.25%, y'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generacion de embeddings con multilingual-e5-large-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/563 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "#     return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "## Each query must come with a one-sentence instruction that describes the task\n",
    "# task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "# queries = [\n",
    "#     get_detailed_instruct(task, 'how much protein should a female eat'),\n",
    "#     get_detailed_instruct(task, '南瓜的家常做法')\n",
    "# ]\n",
    "## No need to add instruction for retrieval documents\n",
    "# documents = []\n",
    "# input_texts = queries + documents\n",
    "\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-large-instruct')\n",
    "for doc in tqdm(documents):    \n",
    "    doc[\"embedding_e5_large_instruct\"] = model.encode(\n",
    "        doc[\"chunk\"], \n",
    "        convert_to_tensor=True, \n",
    "        normalize_embeddings=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** no dió mi ram para usar este modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generacion de embeddings con multilingual-e5-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebasjp/repos/venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'cached_download' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "100%|██████████| 563/563 [01:12<00:00,  7.72it/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('intfloat/multilingual-e5-small')\n",
    "\n",
    "for doc in tqdm(documents):    \n",
    "    doc[\"embedding_e5_small\"] = model.encode(\n",
    "        f\"passage: {doc['chunk']}\",\n",
    "        normalize_embeddings=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generacion de embeddings con paraphrase-multilingual-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebasjp/repos/venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'cached_download' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "100%|██████████| 563/563 [03:37<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    doc[\"embedding_paraphrase_mpnet_base\"] = model.encode(doc['chunk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id_doc', 'chunk', 'embedding_paraphrase_mpnet_base', 'embedding_e5_small'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebasjp/repos/venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'cached_download' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# modelo 1\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_func = HuggingFaceEmbeddings()\n",
    "\n",
    "text_embedding_pairs = zip([doc[\"chunk\"] for doc in documents], [doc[\"embedding_e5_small\"] for doc in documents])\n",
    "faiss = FAISS.from_embeddings(text_embedding_pairs, embeddings_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x7f98949e3100>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 2.4.0.dev0, however, your version is 2.2.2. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/sebasjp/.cache/torch/sentence_transformers/intfloat_multilingual-e5-large-instruct/sentence_xlnet_config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m      4\u001b[0m encode_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalize_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m----> 5\u001b[0m embeddings_func \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m    \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/venv/lib/python3.10/site-packages/langchain_huggingface/embeddings/huggingface.py:61\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43msentence_transformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:95\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSentenceTransformer\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mSequential, FitMixin):\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Loads or creates a SentenceTransformer model that can be used to map sentences / text to embeddings.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m        model_name_or_path (str, optional): If it is a filepath on disc, it loads the model from that path. If it is not a path,\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m            it first tries to download a pre-trained SentenceTransformer model. If that fails, tries to construct a model\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m            from the Hugging Face Hub with that name.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m        modules (Iterable[nn.Module], optional): A list of torch Modules that should be called sequentially, can be used to create custom\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m            SentenceTransformer models from scratch.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m        device (str, optional): Device (like \"cuda\", \"cpu\", \"mps\", \"npu\") that should be used for computation. If None, checks if a GPU\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m            can be used.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m        prompts (Dict[str, str], optional): A dictionary with prompts for the model. The key is the prompt name, the value is the prompt text.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m            The prompt text will be prepended before any text to encode. For example:\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m            `{\"query\": \"query: \", \"passage\": \"passage: \"}` or `{\"clustering\": \"Identify the main category based on the\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m            titles in \"}`.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        default_prompt_name (str, optional): The name of the prompt that should be used by default. If not set,\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m            no prompt will be applied.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m        similarity_fn_name (str or SimilarityFunction, optional): The name of the similarity function to use. Valid options are \"cosine\", \"dot\",\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m            \"euclidean\", and \"manhattan\". If not set, it is automatically set to \"cosine\" if `similarity` or\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m            `similarity_pairwise` are called while `model.similarity_fn_name` is still `None`.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m        cache_folder (str, optional): Path to store models. Can also be set by the SENTENCE_TRANSFORMERS_HOME environment variable.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m        trust_remote_code (bool, optional): Whether or not to allow for custom models defined on the Hub in their own modeling files.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m            This option should only be set to True for repositories you trust and in which you have read the code, as it\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m            will execute code present on the Hub on your local machine.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m        revision (str, optional): The specific model version to use. It can be a branch name, a tag name, or a commit id,\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m            for a stored model on Hugging Face.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m        local_files_only (bool, optional): Whether or not to only look at local files (i.e., do not try to download the model).\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m        token (bool or str, optional): Hugging Face authentication token to download private models.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m        use_auth_token (bool or str, optional): Deprecated argument. Please use `token` instead.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m        truncate_dim (int, optional): The dimension to truncate sentence embeddings to. `None` does no truncation. Truncation is\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m            only applicable during inference when :meth:`SentenceTransformer.encode` is called.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m        model_kwargs (Dict[str, Any], optional): Additional model configuration parameters to be passed to the Huggingface Transformers model.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m            Particularly useful options are:\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m            - ``torch_dtype``: Override the default `torch.dtype` and load the model under a specific `dtype`.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m              The different options are:\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m                    1. ``torch.float16``, ``torch.bfloat16`` or ``torch.float``: load in a specified\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m                    ``dtype``, ignoring the model's ``config.torch_dtype`` if one exists. If not specified - the model will\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m                    get loaded in ``torch.float`` (fp32).\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m                    2. ``\"auto\"`` - A ``torch_dtype`` entry in the ``config.json`` file of the model will be\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m                    attempted to be used. If this entry isn't found then next check the ``dtype`` of the first weight in\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m                    the checkpoint that's of a floating point type and use that as ``dtype``. This will load the model\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m                    using the ``dtype`` it was saved in at the end of the training. It can't be used as an indicator of how\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;124;03m                    the model was trained. Since it could be trained in one of half precision dtypes, but saved in fp32.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m            - ``attn_implementation``: The attention implementation to use in the model (if relevant). Can be any of\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m              `\"eager\"` (manual implementation of the attention), `\"sdpa\"` (using `F.scaled_dot_product_attention\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m              <https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html>`_),\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m              or `\"flash_attention_2\"` (using `Dao-AILab/flash-attention <https://github.com/Dao-AILab/flash-attention>`_).\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m              By default, if available, SDPA will be used for torch>=2.1.1. The default is otherwise the manual `\"eager\"`\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m              implementation.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m            See the `PreTrainedModel.from_pretrained\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m            <https://huggingface.co/docs/transformers/en/main_classes/model#transformers.PreTrainedModel.from_pretrained>`_\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m            documentation for more details.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m        tokenizer_kwargs (Dict[str, Any], optional): Additional tokenizer configuration parameters to be passed to the Huggingface Transformers tokenizer.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m            See the `AutoTokenizer.from_pretrained\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m            <https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained>`_\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m            documentation for more details.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m        config_kwargs (Dict[str, Any], optional): Additional model configuration parameters to be passed to the Huggingface Transformers config.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m            See the `AutoConfig.from_pretrained\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m            <https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoConfig.from_pretrained>`_\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m            documentation for more details.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m        model_card_data (:class:`~sentence_transformers.model_card.SentenceTransformerModelCardData`, optional): A model\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m            card data object that contains information about the model. This is used to generate a model card when saving\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m            the model. If not set, a default model card data object is created.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m        ::\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m            from sentence_transformers import SentenceTransformer\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m            # Load a pre-trained SentenceTransformer model\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m            model = SentenceTransformer('all-mpnet-base-v2')\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m            # Encode some texts\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m            sentences = [\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m                \"The weather is lovely today.\",\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m                \"It's so sunny outside!\",\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m                \"He drove to the stadium.\",\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m            ]\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m            embeddings = model.encode(sentences)\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m            print(embeddings.shape)\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m            # (3, 768)\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m            # Get the similarity scores between all sentences\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m            similarities = model.similarity(embeddings, embeddings)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m            print(similarities)\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m            # tensor([[1.0000, 0.6817, 0.0492],\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m            #         [0.6817, 1.0000, 0.0421],\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m            #         [0.0492, 0.0421, 1.0000]])\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    146\u001b[0m         model_name_or_path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# Note: self._load_sbert_model can also update `self.prompts` and `self.default_prompt_name`\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts \u001b[38;5;241m=\u001b[39m prompts \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[0;32m~/repos/venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:840\u001b[0m, in \u001b[0;36m_load_sbert_model\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    836\u001b[0m chunk\u001b[38;5;241m.\u001b[39mappend(sentence)\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m chunk_size:\n\u001b[1;32m    838\u001b[0m     input_queue\u001b[38;5;241m.\u001b[39mput(\n\u001b[1;32m    839\u001b[0m         [last_chunk_id, batch_size, chunk, prompt_name, prompt, precision, normalize_embeddings]\n\u001b[0;32m--> 840\u001b[0m     )\n\u001b[1;32m    841\u001b[0m     last_chunk_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    842\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/repos/venv/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:135\u001b[0m, in \u001b[0;36mload\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/sebasjp/.cache/torch/sentence_transformers/intfloat_multilingual-e5-large-instruct/sentence_xlnet_config.json'"
     ]
    }
   ],
   "source": [
    "model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "# \"intfloat/multilingual-e5-small\",\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embeddings_func = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(embeddings_func.embed_documents([a[\"chunk\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = documents[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01406619,  0.00473391, -0.0263987 , -0.10681732,  0.03214642,\n",
       "       -0.04709134,  0.03635797,  0.06220098,  0.09489433,  0.01204683,\n",
       "        0.07976241,  0.05135557,  0.03074877, -0.03876662, -0.04131197,\n",
       "       -0.00199246,  0.03582068, -0.06456685, -0.06676188, -0.04475215,\n",
       "        0.0120186 ,  0.03614866, -0.05122845,  0.0667139 ,  0.0443642 ,\n",
       "        0.08165304, -0.04998334,  0.00476078,  0.06206318, -0.05130728,\n",
       "       -0.05314874, -0.00356795,  0.04158295, -0.10153362,  0.06392787,\n",
       "        0.02498712, -0.03653572, -0.00644967,  0.02698488, -0.04979852,\n",
       "       -0.06909255, -0.03419831,  0.01600901,  0.0794198 ,  0.06544348,\n",
       "        0.04306335, -0.06893021,  0.06271015, -0.05432369, -0.05427798,\n",
       "       -0.04316064,  0.07737124, -0.02671421,  0.02386271,  0.05244727,\n",
       "       -0.05437637, -0.07344311, -0.00930264, -0.05723023,  0.01546882,\n",
       "        0.06439141, -0.00023933,  0.01783319,  0.03348359,  0.03487824,\n",
       "        0.05938034, -0.03243915,  0.0258558 , -0.04050863, -0.03722097,\n",
       "       -0.01400993,  0.07125849,  0.00158777,  0.01656424,  0.02297231,\n",
       "        0.04661406,  0.04281425, -0.07370582,  0.01075473, -0.03348953,\n",
       "       -0.03936739, -0.06338384, -0.02964384,  0.04172658, -0.02722738,\n",
       "        0.12910455,  0.05346762, -0.08222603,  0.04809581,  0.00984298,\n",
       "        0.08233523,  0.0621461 , -0.07346914, -0.06524776,  0.01185744,\n",
       "       -0.0581814 , -0.02232728,  0.02684714,  0.07637464, -0.05253309,\n",
       "        0.03493048, -0.07040905,  0.05269598, -0.12239859, -0.03861636,\n",
       "       -0.01703849,  0.00491325, -0.03365766,  0.08269582, -0.06311724,\n",
       "       -0.00085443,  0.02355537,  0.05468259,  0.02837916, -0.10324367,\n",
       "       -0.03327495, -0.00719843, -0.06351276,  0.04538484, -0.0421473 ,\n",
       "        0.08908368, -0.01107384, -0.04071428, -0.06304555, -0.03285083,\n",
       "        0.00638432,  0.0541476 ,  0.02492725, -0.03053838,  0.01509705,\n",
       "        0.0356638 ,  0.04461419,  0.07875126,  0.06009468,  0.05854151,\n",
       "        0.07720819, -0.01573517,  0.01943016, -0.07328343, -0.01933497,\n",
       "       -0.05907339, -0.01970366, -0.02585464,  0.00465746,  0.03997607,\n",
       "        0.07476486,  0.07883254, -0.05069996,  0.03192733, -0.04029231,\n",
       "        0.04224714, -0.05604064,  0.05023438,  0.05603151,  0.01412993,\n",
       "       -0.08651862, -0.0523508 , -0.01267932,  0.02757754,  0.07732797,\n",
       "       -0.08546831, -0.04929564, -0.07425945, -0.00378562, -0.04184606,\n",
       "       -0.05312829,  0.05092498,  0.04465005, -0.05314477, -0.05351433,\n",
       "       -0.0244112 ,  0.03727018, -0.02167507,  0.05648121, -0.04228283,\n",
       "        0.08743232, -0.03430586,  0.05882256,  0.11460049,  0.03896157,\n",
       "       -0.00850324, -0.01193241, -0.07184728, -0.03016661, -0.07551754,\n",
       "       -0.05817664, -0.10967548, -0.00154968,  0.08616553, -0.05322561,\n",
       "        0.00792936,  0.04450445, -0.03468628, -0.07187037, -0.03960705,\n",
       "        0.05893357, -0.06282608,  0.0543366 ,  0.04689908,  0.03441661,\n",
       "        0.05620685, -0.02346704,  0.06502421, -0.00945901,  0.03534135,\n",
       "        0.01806584, -0.03966857,  0.076232  , -0.02527297,  0.01048552,\n",
       "        0.03085817, -0.03389386, -0.0412878 ,  0.03307831, -0.03926359,\n",
       "       -0.02629682, -0.0161085 ,  0.06158688, -0.04343031, -0.01392373,\n",
       "       -0.00373105, -0.00435181,  0.05661016, -0.05202509,  0.00966555,\n",
       "        0.0565083 ,  0.00522744, -0.06174187, -0.0468635 ,  0.03631281,\n",
       "       -0.05446541,  0.01906824, -0.05663412, -0.05349742, -0.05248158,\n",
       "       -0.07296635, -0.02009266,  0.04958105,  0.04471089, -0.06276562,\n",
       "       -0.08569747, -0.02910428,  0.03105474, -0.07737099,  0.04266687,\n",
       "       -0.03975442, -0.00611621, -0.00566711, -0.04579153,  0.02894251,\n",
       "        0.06307963, -0.04406612, -0.09648801, -0.07397291, -0.0460777 ,\n",
       "        0.03157632, -0.00017344,  0.063359  , -0.04327856,  0.02426649,\n",
       "        0.01381134, -0.05160518,  0.07370013,  0.07777611, -0.0006993 ,\n",
       "       -0.03901664, -0.0171974 , -0.05223155, -0.03335966, -0.00505867,\n",
       "       -0.0418788 ,  0.03152014,  0.01015149,  0.01936612, -0.0362174 ,\n",
       "       -0.0072107 , -0.0253189 ,  0.07048201, -0.05127874, -0.00486115,\n",
       "        0.07046087,  0.05923225,  0.02359608,  0.06861448,  0.05066292,\n",
       "       -0.04343199,  0.01139221,  0.05991514, -0.02184843, -0.02152313,\n",
       "       -0.01965046, -0.04527711,  0.05733999, -0.03671746,  0.06491445,\n",
       "        0.06897521, -0.06182168,  0.05919421, -0.04971294, -0.00058297,\n",
       "        0.00672182, -0.00130214, -0.01456481,  0.06905185, -0.07664414,\n",
       "        0.06660607,  0.05087574,  0.00984997,  0.06061666,  0.04627629,\n",
       "        0.08386288,  0.08757777, -0.09071692, -0.02617263,  0.03706739,\n",
       "        0.06556019,  0.00347839,  0.10527225, -0.04737187, -0.03628873,\n",
       "       -0.09368456, -0.05530262, -0.00754413, -0.03131277,  0.04947862,\n",
       "        0.08093808, -0.01336475, -0.03484882,  0.07626197, -0.0572531 ,\n",
       "        0.06590173, -0.07965043, -0.08765246,  0.04575947, -0.05668679,\n",
       "       -0.04203362,  0.01754885,  0.00076069, -0.04953894, -0.0465692 ,\n",
       "        0.01637078,  0.09676738, -0.0322935 ,  0.04364742, -0.00697857,\n",
       "       -0.06078238,  0.03598691, -0.05603817, -0.02620786,  0.09138794,\n",
       "        0.01807606, -0.08832245,  0.02703295, -0.0041624 , -0.02216099,\n",
       "        0.02463122, -0.05006025, -0.03222355,  0.06465196,  0.01409933,\n",
       "       -0.08317745, -0.0189239 ,  0.0531413 ,  0.09293468,  0.08085434,\n",
       "        0.06444226, -0.04538095, -0.05368758,  0.01622438, -0.06997518,\n",
       "        0.04829604,  0.03824681, -0.02988109,  0.00647711,  0.01345756,\n",
       "       -0.06313036, -0.04010644,  0.06272446, -0.04976515, -0.03861867,\n",
       "       -0.01840422,  0.05207594,  0.01724576,  0.02607023], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a[\"embedding_e5_small\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
